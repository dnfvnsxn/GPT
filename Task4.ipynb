{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108d0ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제가 알기로는 Aaronson은 유죄로 판결받았습니다.\n",
      "그가 쓴 메시지는 \"FREEDOM IS SLAVERY\"와 \"TWO AND TWO MAKE FIVE\" 그리고 \"GOD IS POWER\"입니다.\n",
      "Julia는 Winston과 함께 이야기 중에 등장하는 여성 캐릭터입니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Julia는 Winston과 함께 이야기 중에 등장하는 여성 캐릭터입니다.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "def load_history(_):\n",
    "    return memory.load_memory_variables({})[\"history\"]\n",
    "\n",
    "loader = UnstructuredFileLoader(\"./files/doc2.txt\")\n",
    "\n",
    "\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "cache_dir = LocalFileStore(\"./.cache/\")\n",
    "embeddings = OpenAIEmbeddings()\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)\n",
    "vectorstore = FAISS.from_documents(docs, cached_embeddings)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "def stuff_docs(documents):\n",
    "    return \"\\n\\n\".join(d.page_content for d in documents)\n",
    "\n",
    "context_chain = retriever | RunnableLambda(stuff_docs)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer ONLY using the context below. \"\n",
    "            \"If you don't know, say you don't know.\\n\\n\"\n",
    "            \"----- CONTEXT -----\\n{context}\\n--------------------\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": context_chain,\n",
    "        \"history\": RunnableLambda(load_history),\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "def ask(question: str):\n",
    "    result = chain.invoke(question)\n",
    "    memory.save_context({\"input\": question}, {\"output\": result.content})\n",
    "    print(result.content)\n",
    "    return result.content\n",
    "\n",
    "ask(\"Aaronson 은 유죄인가요?\")\n",
    "ask(\"그가 테이블에 어떤 메시지를 썼나요?\")\n",
    "ask(\"Julia 는 누구인가요?\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
